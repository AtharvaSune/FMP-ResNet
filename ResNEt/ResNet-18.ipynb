{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 30, 30, 32)   896         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 28, 28, 64)   18496       conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 9, 9, 64)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 9, 9, 64)     36928       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 9, 9, 64)     256         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 9, 9, 64)     256         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 9, 9, 64)     0           batch_normalization_61[0][0]     \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 9, 9, 64)     0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 9, 9, 64)     36928       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 9, 9, 64)     256         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 9, 9, 64)     256         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 9, 9, 64)     0           batch_normalization_63[0][0]     \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 9, 9, 64)     0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 9, 9, 64)     36928       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 9, 9, 64)     256         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 9, 9, 64)     256         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 9, 9, 64)     0           batch_normalization_65[0][0]     \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 9, 9, 64)     0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 9, 9, 64)     36928       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 9, 9, 64)     256         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 9, 9, 64)     256         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 9, 9, 64)     0           batch_normalization_67[0][0]     \n",
      "                                                                 activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 9, 9, 64)     0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 9, 9, 64)     36928       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 9, 9, 64)     256         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 9, 9, 64)     256         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 9, 9, 64)     0           batch_normalization_69[0][0]     \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 9, 9, 64)     0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 9, 9, 64)     36928       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 9, 9, 64)     256         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 9, 9, 64)     256         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 9, 9, 64)     0           batch_normalization_71[0][0]     \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 9, 9, 64)     0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 9, 9, 64)     36928       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 9, 9, 64)     256         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 9, 9, 64)     256         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 9, 9, 64)     0           batch_normalization_73[0][0]     \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 9, 9, 64)     0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 9, 9, 64)     36928       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 9, 9, 64)     256         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 9, 9, 64)     256         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 9, 9, 64)     0           batch_normalization_75[0][0]     \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 9, 9, 64)     0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 9, 9, 64)     36928       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 9, 9, 64)     256         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 9, 9, 64)     256         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 9, 9, 64)     0           batch_normalization_77[0][0]     \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 9, 9, 64)     0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 9, 9, 64)     36928       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 9, 9, 64)     256         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 9, 9, 64)     256         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 9, 9, 64)     0           batch_normalization_79[0][0]     \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 9, 9, 64)     0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 7, 7, 64)     36928       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 2, 2, 64)     0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 256)          0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          65792       flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           2570        dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 868,362\n",
      "Trainable params: 865,802\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/195 [============================>.] - ETA: 0s - loss: 1.9452 - acc: 0.3059\n",
      "Epoch 00001: val_loss improved from inf to 2.33582, saving model to Model.hdf5\n",
      "195/195 [==============================] - 24s 121ms/step - loss: 1.9425 - acc: 0.3073 - val_loss: 2.3358 - val_acc: 0.1163\n",
      "Epoch 2/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 1.5461 - acc: 0.4309\n",
      "Epoch 00002: val_loss improved from 2.33582 to 2.07772, saving model to Model.hdf5\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 1.5444 - acc: 0.4313 - val_loss: 2.0777 - val_acc: 0.2580\n",
      "Epoch 3/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 1.3940 - acc: 0.4951\n",
      "Epoch 00003: val_loss improved from 2.07772 to 1.39476, saving model to Model.hdf5\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 1.3924 - acc: 0.4955 - val_loss: 1.3948 - val_acc: 0.4884\n",
      "Epoch 4/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 1.2779 - acc: 0.5388\n",
      "Epoch 00004: val_loss improved from 1.39476 to 1.32269, saving model to Model.hdf5\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 1.2770 - acc: 0.5390 - val_loss: 1.3227 - val_acc: 0.5323\n",
      "Epoch 5/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 1.1634 - acc: 0.5879\n",
      "Epoch 00005: val_loss did not improve from 1.32269\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 1.1639 - acc: 0.5873 - val_loss: 1.4856 - val_acc: 0.4929\n",
      "Epoch 6/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 1.0735 - acc: 0.6195\n",
      "Epoch 00006: val_loss did not improve from 1.32269\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 1.0728 - acc: 0.6196 - val_loss: 2.0718 - val_acc: 0.3759\n",
      "Epoch 7/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 1.0250 - acc: 0.6340\n",
      "Epoch 00007: val_loss did not improve from 1.32269\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 1.0239 - acc: 0.6340 - val_loss: 1.9518 - val_acc: 0.4237\n",
      "Epoch 8/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.9810 - acc: 0.6545\n",
      "Epoch 00008: val_loss improved from 1.32269 to 1.22509, saving model to Model.hdf5\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 0.9803 - acc: 0.6547 - val_loss: 1.2251 - val_acc: 0.5836\n",
      "Epoch 9/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.9269 - acc: 0.6780\n",
      "Epoch 00009: val_loss did not improve from 1.22509\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 0.9251 - acc: 0.6785 - val_loss: 1.7843 - val_acc: 0.4829\n",
      "Epoch 10/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.8738 - acc: 0.6943\n",
      "Epoch 00010: val_loss did not improve from 1.22509\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 0.8745 - acc: 0.6943 - val_loss: 1.2945 - val_acc: 0.5781\n",
      "Epoch 11/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.8749 - acc: 0.6914\n",
      "Epoch 00011: val_loss improved from 1.22509 to 1.04561, saving model to Model.hdf5\n",
      "195/195 [==============================] - 9s 44ms/step - loss: 0.8747 - acc: 0.6914 - val_loss: 1.0456 - val_acc: 0.6389\n",
      "Epoch 12/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.8246 - acc: 0.7124\n",
      "Epoch 00012: val_loss did not improve from 1.04561\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 0.8248 - acc: 0.7121 - val_loss: 1.1108 - val_acc: 0.6227\n",
      "Epoch 13/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.7756 - acc: 0.7302\n",
      "Epoch 00013: val_loss did not improve from 1.04561\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 0.7746 - acc: 0.7305 - val_loss: 1.0791 - val_acc: 0.6363\n",
      "Epoch 14/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.7789 - acc: 0.7311\n",
      "Epoch 00014: val_loss improved from 1.04561 to 0.98895, saving model to Model.hdf5\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 0.7789 - acc: 0.7309 - val_loss: 0.9890 - val_acc: 0.6664\n",
      "Epoch 15/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.7569 - acc: 0.7377\n",
      "Epoch 00015: val_loss did not improve from 0.98895\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 0.7558 - acc: 0.7384 - val_loss: 1.3017 - val_acc: 0.5964\n",
      "Epoch 16/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.7487 - acc: 0.7400\n",
      "Epoch 00016: val_loss improved from 0.98895 to 0.91447, saving model to Model.hdf5\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 0.7486 - acc: 0.7401 - val_loss: 0.9145 - val_acc: 0.6939\n",
      "Epoch 17/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.6920 - acc: 0.7607\n",
      "Epoch 00017: val_loss did not improve from 0.91447\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 0.6913 - acc: 0.7611 - val_loss: 1.0266 - val_acc: 0.6581\n",
      "Epoch 18/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.6744 - acc: 0.7665\n",
      "Epoch 00018: val_loss did not improve from 0.91447\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 0.6743 - acc: 0.7668 - val_loss: 0.9484 - val_acc: 0.6774\n",
      "Epoch 19/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.6785 - acc: 0.7636\n",
      "Epoch 00019: val_loss improved from 0.91447 to 0.91334, saving model to Model.hdf5\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 0.6786 - acc: 0.7639 - val_loss: 0.9133 - val_acc: 0.6883\n",
      "Epoch 20/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.6744 - acc: 0.7702\n",
      "Epoch 00020: val_loss improved from 0.91334 to 0.86114, saving model to Model.hdf5\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 0.6738 - acc: 0.7704 - val_loss: 0.8611 - val_acc: 0.7079\n",
      "Epoch 21/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.5998 - acc: 0.7905\n",
      "Epoch 00021: val_loss did not improve from 0.86114\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 0.5996 - acc: 0.7905 - val_loss: 0.8893 - val_acc: 0.7021\n",
      "Epoch 22/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.6090 - acc: 0.7898\n",
      "Epoch 00022: val_loss did not improve from 0.86114\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 0.6096 - acc: 0.7895 - val_loss: 0.8769 - val_acc: 0.7077\n",
      "Epoch 23/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.6211 - acc: 0.7850\n",
      "Epoch 00023: val_loss did not improve from 0.86114\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 0.6222 - acc: 0.7846 - val_loss: 0.8945 - val_acc: 0.7029\n",
      "Epoch 24/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.6217 - acc: 0.7824\n",
      "Epoch 00024: val_loss improved from 0.86114 to 0.76129, saving model to Model.hdf5\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 0.6230 - acc: 0.7816 - val_loss: 0.7613 - val_acc: 0.7465\n",
      "Epoch 25/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.5445 - acc: 0.8090\n",
      "Epoch 00025: val_loss did not improve from 0.76129\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 0.5433 - acc: 0.8095 - val_loss: 0.8083 - val_acc: 0.7303\n",
      "Epoch 26/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.5633 - acc: 0.8068\n",
      "Epoch 00026: val_loss did not improve from 0.76129\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 0.5637 - acc: 0.8066 - val_loss: 1.1410 - val_acc: 0.6529\n",
      "Epoch 27/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.5561 - acc: 0.8066\n",
      "Epoch 00027: val_loss did not improve from 0.76129\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 0.5569 - acc: 0.8061 - val_loss: 0.8646 - val_acc: 0.7115\n",
      "Epoch 28/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.5496 - acc: 0.8120\n",
      "Epoch 00028: val_loss did not improve from 0.76129\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 0.5491 - acc: 0.8123 - val_loss: 0.7685 - val_acc: 0.7449\n",
      "Epoch 29/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.4913 - acc: 0.8319\n",
      "Epoch 00029: val_loss did not improve from 0.76129\n",
      "195/195 [==============================] - 8s 43ms/step - loss: 0.4924 - acc: 0.8317 - val_loss: 1.3107 - val_acc: 0.6464\n",
      "Epoch 30/30\n",
      "193/195 [============================>.] - ETA: 0s - loss: 0.5059 - acc: 0.8225\n",
      "Epoch 00030: val_loss did not improve from 0.76129\n",
      "195/195 [==============================] - 8s 42ms/step - loss: 0.5061 - acc: 0.8224 - val_loss: 0.9628 - val_acc: 0.6969\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7b9724a03b2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).batch(64).shuffle(50000)\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "train_dataset = train_dataset.repeat()\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_test, y_test)).batch(5000).shuffle(10000)\n",
    "valid_dataset = valid_dataset.map(\n",
    "    lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "valid_dataset = valid_dataset.repeat()\n",
    "\n",
    "\n",
    "\n",
    "def res_net_block(input_data, filters, conv_size):\n",
    "    x = layers.Conv2D(filters, conv_size, activation='relu',\n",
    "                      padding='same')(input_data)\n",
    "    x = layers.BatchNormalization(axis = -1)(x)\n",
    "    x = layers.Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "    x = layers.BatchNormalization(axis = -1)(x)\n",
    "    x = layers.Add()([x, input_data])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def non_res_block(input_data, filters, conv_size):\n",
    "    x = layers.Conv2D(filters, conv_size, activation='relu',\n",
    "                      padding='same')(input_data)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(filters, conv_size,\n",
    "                      activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "num_res_net_blocks = 10\n",
    "for i in range(num_res_net_blocks):\n",
    "    x = res_net_block(x, 64, 3)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "res_net_model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    # Write TensorBoard logs to `./logs` directory\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='./log/{}'.format(dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")), write_images=True),\n",
    "]\n",
    "res_net_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['acc'])\n",
    "\n",
    "print(res_net_model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint('Model.hdf5', monitor='val_loss', save_best_only = True, verbose=1, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "#model.load_weights('Model.hdf5')\n",
    "epochs = 10\n",
    "results = res_net_model.fit(train_dataset, epochs=30, steps_per_epoch=195,\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=3, callbacks=callbacks_list)\n",
    "\n",
    "# plot epoch vs accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(results.history['acc'])\n",
    "plt.plot(results.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
